apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    model.aibrix.ai/name: qwen3-8b
    model.aibrix.ai/port: "8000"
  name: qwen3-8b
  namespace: default
spec:
  replicas: 2
  selector:
    matchLabels:
      model.aibrix.ai/name: qwen3-8b
  template:
    metadata:
      labels:
        model.aibrix.ai/name: qwen3-8b
    spec:
      containers:
        - name: vllm-openai
          image: kvcache-container-image-hb2-cn-beijing.cr.volces.com/aibrix/vllm-openai:v0.9.2-cu128-nixl-v0.4.1-lmcache-0.3.1.post1
          command: ["sh", "-c"]
          args:
            - |
              python3 -m vllm.entrypoints.openai.api_server \
              --host "0.0.0.0" \
              --port "8000" \
              --uvicorn-log-level warning \
              --model /models/Qwen3-8B \
              --served-model-name qwen3-8b
          resources:
            limits:
              nvidia.com/gpu: 1
          volumeMounts:
            - name: model-vol
              mountPath: /models
              readOnly: true
            - mountPath: /dev/shm
              name: shared-mem
          securityContext:
            capabilities:
              add:
                - IPC_LOCK
      volumes:
        - name: model-vol
          hostPath:
            path: /data01/models
            type: Directory
        - emptyDir:
            medium: Memory
          name: shared-mem
